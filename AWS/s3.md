 s3 provides **strong** read after write consistency for `PUT` and `DELETE`. 

s3 mental model - object storage service that stores **data as objects** in buckets 
- object = any file

# buckets
buckets are private by default (but can toggle visibility)
- gives acls through bucket policies, acls, s3 access points (AP) 
- buckets have a nice property that they are *content addressable* 
	- an object called `a/b.jpg` is accessible via `<bucket_url>/a/b.jpg`

# objects 
- stores content + meta
- if versioning is enabled, the object key is `<bucket>/<object key>/<version>` 

# bucket policy 
- resource based IAM policy 
- max 20 kb in size 
- can do wild cards -> base specificity is object 
	- what if i have public bucket but a restrictive bucket policy?

# s3 access points 
- named network endpoints 
- can configure block public access! 
	- is it possible to have a private AP on a public bucket?
	- is it possible to have a AP that exposes only a subset of objects? eg: bucket has `a/b/...` and `a/c/...` and i block all access on `a/c/...`  

# ACLs 
- r/w access for users for individual buckets + objects 
- (not really req - docs suggest keeping ACLs disabled)

# s3 data consistency model
#consistency #s3 
- strong read after write consistency for `PUT + DELETE` **of objects**
	- an object is **a single file** 
- updates to a single key (read: file) are **atomic** 

> [!NOTE] Gotchas 
> 1. s3 has no object locking for concurrent writes to same object - their model is last write wins (LWW) 
> 2. updates are *key-based* - there is no atomicity *across keys*. this means, for example, if we present a logical view of `a/b/c` + `a/b/d` and user wants to do `a/b/... -> a/e/...`, we handle locking ourselves 

## concurrency 
- concurrent writes have lww semantics - you don't know what the end state is unless you query!!!
- writes are considered **consistent only after ack** 
- important - we have 2 compute instances (potentially more), which can issue writes out to s3!! (unless we got partition key based on user) 
- 